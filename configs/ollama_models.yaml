# --- GLOBAL SETTINGS ---

OLLAMA_BASE_URL: "http://localhost:11434"

# --- EMBEDDING MODEL (For RAG/ChromaDB) ---

EMBEDDING_MODEL:
  model: "nomic-embed-text"
  base_url: "http://localhost:11434"

# --- AGENT-SPECIFIC LLM SETTINGS ---

AGENT_MODELS:
  # Orchestrator Agent (The Supervisor)
  Orchestrator:
    model: "gemma2:9b"
    temperature: 0.0
    system_prompt_file: "configs/system_prompts/orchestrator_prompt.txt"
    num_ctx: 2048
    format: "json"

  # Synthesizer Agent (The Final Voice)
  Synthesizer:
    model: "gemma2:9b"
    temperature: 0.5
    system_prompt_file: "configs/system_prompts/synthesizer_prompt.txt"
    num_ctx: 4096
    format: ""

  Professor:
    model: "gemma2:9b"
    temperature: 0.1
    system_prompt_file: "configs/system_prompts/professor_prompt.txt"
    num_ctx: 4096
    format: ""

  Researcher:
    model: "gemma2:9b"
    temperature: 0.3
    system_prompt_file: "configs/system_prompts/researcher_prompt.txt"
    num_predict: 512

  NoteTaker:
    model: "gemma2:9b"
    temperature: 0.7
    system_prompt_file: "configs/system_prompts/note_taker_prompt.txt"
    format: ""

  Communicator:
    model: "gemma2:9b"
    temperature: 0.2
    system_prompt_file: "configs/system_prompts/communicator_prompt.txt"
    format: ""

  Concierge:
    model: "gemma2:9b"
    temperature: 0.4
    system_prompt_file: "configs/system_prompts/concierge_prompt.txt"
    format: ""

  Secretary:
    model: "gemma2:9b"
    temperature: 0.1
    system_prompt_file: "configs/system_prompts/secretary_prompt.txt"
    format: ""

  Accountant:
    model: "gemma2:9b"
    temperature: 0.05
    system_prompt_file: "configs/system_prompts/accountant_prompt.txt"
    format: ""

  Responder:
    model: "gemma2:9b"
    temperature: 0.6
    system_prompt_file: "configs/system_prompts/responder_prompt.txt"
    num_ctx: 4096
    format: ""
